# Python-ML-Classifiers (KNN + Naive Bayes)

Proyecto en **Python** que implementa un pequeÃ±o â€œframeworkâ€ acadÃ©mico de **clasificaciÃ³n supervisada** con:

- **KNN propio** (desde cero) con distancia euclÃ­dea y normalizaciÃ³n opcional.
- **KNN con scikit-learn** (para comparar resultados y validar la implementaciÃ³n).
- **Naive Bayes** (mixto: nominal + continuo con Gaussiana) con Laplace opcional.
- **Carga y codificaciÃ³n de datasets** (atributos nominales â†’ enteros, continuos â†’ float).
- **Estrategias de validaciÃ³n**: *hold-out* (validaciÃ³n simple) y **k-fold cross-validation**.
- Notebook **`MainP1.ipynb`** con experimentos, comparaciÃ³n contra sklearn y resultados.

> El objetivo principal es practicar diseÃ±o modular, validaciÃ³n experimental y fundamentos de ML clÃ¡sicos (KNN y Naive Bayes).

---

## ğŸ“ Estructura del proyecto

```
.
â”œâ”€â”€ Datos.py
â”œâ”€â”€ EstrategiaParticionado.py
â”œâ”€â”€ Clasificador.py
â”œâ”€â”€ ClasificadorKNN.py
â”œâ”€â”€ ClasificadorKNNSK.py
â”œâ”€â”€ ClasificadorNB.py
â””â”€â”€ MainP1.ipynb
```

### Â¿QuÃ© hace cada archivo?

- **`Datos.py`**
  - Lee un CSV con `pandas`.
  - Detecta atributos nominales (tipo `object`) y **trata siempre la Ãºltima columna como clase**.
  - Construye:
    - `datos.datos` â†’ matriz `numpy` con todo numÃ©rico (incluida la clase).
    - `datos.nominalAtributos` â†’ lista `bool` indicando quÃ© columnas son nominales.
    - `datos.diccionarios` â†’ diccionario por columna para codificar valores nominales.
  - `extraeDatos(idx)` devuelve un subconjunto por Ã­ndices.
  - `estandarizarDatos()` estandariza **solo atributos continuos** (z-score).

- **`EstrategiaParticionado.py`**
  - Define `Particion(indicesTrain, indicesTest)`.
  - Define interfaz `EstrategiaParticionado.creaParticiones(...)`.
  - Implementa:
    - `ValidacionSimple(proporcionTrain, numeroEjecuciones)` (*hold-out*).
    - `ValidacionCruzada(k)` (k-fold).

- **`Clasificador.py`**
  - Clase base abstracta con:
    - `entrenamiento(...)`
    - `clasifica(...)`
  - Implementa:
    - `validacion(particionado, dataset, clasificador, laplace=False, seed=None)`
    - `error(datos, pred)` (mÃ©trica usada en validaciÃ³n; ver notas abajo).

- **`ClasificadorKNN.py`**
  - ImplementaciÃ³n propia de **KNN**.
  - Normaliza usando medias y desviaciones del train si `normalizar=True`.
  - Calcula distancia euclÃ­dea y vota por mayorÃ­a sobre los `k` vecinos.

- **`ClasificadorKNNSK.py`**
  - KNN con **scikit-learn** (`KNeighborsClassifier`) + `StandardScaler` opcional.
  - Ãštil para comprobar que la implementaciÃ³n propia se comporta razonablemente.

- **`ClasificadorNB.py`**
  - ImplementaciÃ³n de **Naive Bayes**:
    - Para atributos nominales: probabilidades condicionadas `P(x_i | clase)`.
    - Para continuos: modelo **Gaussiano** (densidad normal con media y desviaciÃ³n).
  - Calcula a-prioris `P(clase)` y predice la clase con mayor probabilidad.

- **`MainP1.ipynb`**
  - Notebook con experimentos:
    - EstÃ¡ndarizaciÃ³n vs `StandardScaler`.
    - Resultados de Naive Bayes y KNN.
    - ValidaciÃ³n simple y cruzada.

---

## ğŸ§  Flujo general de uso

1) Cargar datos desde CSV con `Datos` (codifica nominales a enteros).  
2) Elegir una estrategia de particionado (`ValidacionSimple` o `ValidacionCruzada`).  
3) Elegir clasificador (KNN propio, KNN sklearn o Naive Bayes).  
4) Ejecutar validaciÃ³n con `Clasificador.validacion(...)` para obtener un vector de mÃ©tricas por particiÃ³n.

---

## âœ… Estrategias de validaciÃ³n

### 1) ValidaciÃ³n simple (hold-out) â€” `ValidacionSimple`
- Selecciona aleatoriamente un porcentaje de filas para train (`proporcionTrain`).
- El resto se usa como test.
- **Nota:** aunque existe el parÃ¡metro `numeroEjecuciones`, en esta versiÃ³n se construye **una particiÃ³n** (una ejecuciÃ³n).

### 2) ValidaciÃ³n cruzada k-fold â€” `ValidacionCruzada`
- Baraja el dataset y lo divide en `k` folds.
- Para cada fold `i`:
  - test = fold `i`
  - train = resto de folds
- Devuelve `k` particiones.

---

## ğŸ§© Clasificadores en detalle

## 1) KNN propio â€” `ClasificadorKNN`
**Idea:** un punto se clasifica segÃºn las etiquetas de sus `k` vecinos mÃ¡s cercanos.

- Entrenamiento:
  - Guarda `datosTrain`.
  - Si `normalizar=True`, estandariza cada atributo continuo del train y guarda `media/std` por columna.
- PredicciÃ³n:
  - Si `normalizar=True`, estandariza el test usando **la media/std del train**.
  - Calcula distancias euclÃ­deas entre el punto de test y todos los de train.
  - Ordena por distancia y toma los `k` vecinos.
  - Predice por **mayorÃ­a** (`Counter.most_common(1)`).

ParÃ¡metros:
- `k`: nÃºmero de vecinos.
- `distancia`: en este cÃ³digo solo se usa `"euclidea"`.
- `normalizar`: recomendado si hay atributos con escalas distintas.

## 2) KNN scikit-learn â€” `ClasificadorKNNSK`
Permite comparar con una implementaciÃ³n estÃ¡ndar:
- `KNeighborsClassifier(n_neighbors=k, metric=distancia)`
- `StandardScaler` opcional si `normalizar=True`

## 3) Naive Bayes â€” `ClaificadorNaiveBayes`
**Idea:** asume independencia condicional de atributos dado la clase.

- Calcula a-prioris:
  - `P(clase) = #clase / #total`
- Para atributos nominales:
  - `P(valor | clase)` usando conteo por clase.
  - Laplace opcional (suma 1 al conteo si `laplace=True`).
- Para atributos continuos:
  - Modela `P(x | clase)` con una **Gaussiana**.
  - En esta implementaciÃ³n se guardan medias/std por atributo (nota: ver â€œDetalles a revisarâ€).

PredicciÃ³n:
- Para cada clase, calcula la probabilidad proporcional:
  - `P(clase) * Î _i P(x_i | clase)`
- Devuelve la clase con probabilidad mÃ¡xima.

---

## â–¶ï¸ CÃ³mo ejecutar

### OpciÃ³n A: Notebook (recomendado)
Abrir `MainP1.ipynb` y ejecutar celdas (Jupyter / VS Code).

### OpciÃ³n B: Script rÃ¡pido (ejemplo)
Puedes crear un `main.py` con algo asÃ­:

```python
from Datos import Datos
from EstrategiaParticionado import ValidacionCruzada
from ClasificadorKNN import ClasificadorKNN
from Clasificador import Clasificador

datos = Datos("tu_dataset.csv", print_val=False)
particionado = ValidacionCruzada(k=5)

knn = ClasificadorKNN(k=5, normalizar=True)
base = Clasificador()  # En la prÃ¡ctica, llamarÃ­as a validaciÃ³n desde una instancia concreta o moverÃ­as validacion() a funciÃ³n util.

# Si prefieres: usa el mÃ©todo validacion desde una instancia de tu clasificador base
errores = base.validacion(particionado, datos, knn)
print(errores)
print("Media:", sum(errores) / len(errores))
```

> Nota: si vas a usarlo â€œen limpioâ€, lo ideal es convertir `validacion(...)` en mÃ©todo estÃ¡tico o funciÃ³n de utilidad y no instanciar `Clasificador` directamente (es abstracta).


## ğŸ› ï¸ Dependencias

- `numpy`
- `pandas`
- `scipy` (para distancia euclÃ­dea en KNN propio)
- `scikit-learn` (solo para `ClasificadorKNNSK` y comparativas del notebook)
- Jupyter (si usas el notebook)

---

## ğŸ‘¤ Autor

Santiago de Prada Lorenzo
