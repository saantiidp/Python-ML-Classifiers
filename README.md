# Python-ML-Classifiers (KNN + Naive Bayes)

Proyecto en **Python** que implementa un peque√±o ‚Äúframework‚Äù acad√©mico de **clasificaci√≥n supervisada** con:

- **KNN propio** (desde cero) con distancia eucl√≠dea y normalizaci√≥n opcional.
- **KNN con scikit-learn** (para comparar resultados y validar la implementaci√≥n).
- **Naive Bayes** (mixto: nominal + continuo con Gaussiana) con Laplace opcional.
- **Carga y codificaci√≥n de datasets** (atributos nominales ‚Üí enteros, continuos ‚Üí float).
- **Estrategias de validaci√≥n**: *hold-out* (validaci√≥n simple) y **k-fold cross-validation**.
- Notebook **`MainP1.ipynb`** con experimentos, comparaci√≥n contra sklearn y resultados.

> El objetivo principal es practicar dise√±o modular, validaci√≥n experimental y fundamentos de ML cl√°sicos (KNN y Naive Bayes).

---

## üìÅ Estructura del proyecto

```
.
‚îú‚îÄ‚îÄ Datos.py
‚îú‚îÄ‚îÄ EstrategiaParticionado.py
‚îú‚îÄ‚îÄ Clasificador.py
‚îú‚îÄ‚îÄ ClasificadorKNN.py
‚îú‚îÄ‚îÄ ClasificadorKNNSK.py
‚îú‚îÄ‚îÄ ClasificadorNB.py
‚îî‚îÄ‚îÄ MainP1.ipynb
```

### ¬øQu√© hace cada archivo?

- **`Datos.py`**
  - Lee un CSV con `pandas`.
  - Detecta atributos nominales (tipo `object`) y **trata siempre la √∫ltima columna como clase**.
  - Construye:
    - `datos.datos` ‚Üí matriz `numpy` con todo num√©rico (incluida la clase).
    - `datos.nominalAtributos` ‚Üí lista `bool` indicando qu√© columnas son nominales.
    - `datos.diccionarios` ‚Üí diccionario por columna para codificar valores nominales.
  - `extraeDatos(idx)` devuelve un subconjunto por √≠ndices.
  - `estandarizarDatos()` estandariza **solo atributos continuos** (z-score).

- **`EstrategiaParticionado.py`**
  - Define `Particion(indicesTrain, indicesTest)`.
  - Define interfaz `EstrategiaParticionado.creaParticiones(...)`.
  - Implementa:
    - `ValidacionSimple(proporcionTrain, numeroEjecuciones)` (*hold-out*).
    - `ValidacionCruzada(k)` (k-fold).

- **`Clasificador.py`**
  - Clase base abstracta con:
    - `entrenamiento(...)`
    - `clasifica(...)`
  - Implementa:
    - `validacion(particionado, dataset, clasificador, laplace=False, seed=None)`
    - `error(datos, pred)` (m√©trica usada en validaci√≥n; ver notas abajo).

- **`ClasificadorKNN.py`**
  - Implementaci√≥n propia de **KNN**.
  - Normaliza usando medias y desviaciones del train si `normalizar=True`.
  - Calcula distancia eucl√≠dea y vota por mayor√≠a sobre los `k` vecinos.

- **`ClasificadorKNNSK.py`**
  - KNN con **scikit-learn** (`KNeighborsClassifier`) + `StandardScaler` opcional.
  - √ötil para comprobar que la implementaci√≥n propia se comporta razonablemente.

- **`ClasificadorNB.py`**
  - Implementaci√≥n de **Naive Bayes**:
    - Para atributos nominales: probabilidades condicionadas `P(x_i | clase)`.
    - Para continuos: modelo **Gaussiano** (densidad normal con media y desviaci√≥n).
  - Calcula a-prioris `P(clase)` y predice la clase con mayor probabilidad.

- **`MainP1.ipynb`**
  - Notebook con experimentos:
    - Est√°ndarizaci√≥n vs `StandardScaler`.
    - Resultados de Naive Bayes y KNN.
    - Validaci√≥n simple y cruzada.

---

## üß† Flujo general de uso

1) Cargar datos desde CSV con `Datos` (codifica nominales a enteros).  
2) Elegir una estrategia de particionado (`ValidacionSimple` o `ValidacionCruzada`).  
3) Elegir clasificador (KNN propio, KNN sklearn o Naive Bayes).  
4) Ejecutar validaci√≥n con `Clasificador.validacion(...)` para obtener un vector de m√©tricas por partici√≥n.

---

## ‚úÖ Estrategias de validaci√≥n

### 1) Validaci√≥n simple (hold-out) ‚Äî `ValidacionSimple`
- Selecciona aleatoriamente un porcentaje de filas para train (`proporcionTrain`).
- El resto se usa como test.
- **Nota:** aunque existe el par√°metro `numeroEjecuciones`, en esta versi√≥n se construye **una partici√≥n** (una ejecuci√≥n).

### 2) Validaci√≥n cruzada k-fold ‚Äî `ValidacionCruzada`
- Baraja el dataset y lo divide en `k` folds.
- Para cada fold `i`:
  - test = fold `i`
  - train = resto de folds
- Devuelve `k` particiones.

---

## üß© Clasificadores en detalle

## 1) KNN propio ‚Äî `ClasificadorKNN`
**Idea:** un punto se clasifica seg√∫n las etiquetas de sus `k` vecinos m√°s cercanos.

- Entrenamiento:
  - Guarda `datosTrain`.
  - Si `normalizar=True`, estandariza cada atributo continuo del train y guarda `media/std` por columna.
- Predicci√≥n:
  - Si `normalizar=True`, estandariza el test usando **la media/std del train**.
  - Calcula distancias eucl√≠deas entre el punto de test y todos los de train.
  - Ordena por distancia y toma los `k` vecinos.
  - Predice por **mayor√≠a** (`Counter.most_common(1)`).

Par√°metros:
- `k`: n√∫mero de vecinos.
- `distancia`: en este c√≥digo solo se usa `"euclidea"`.
- `normalizar`: recomendado si hay atributos con escalas distintas.

## 2) KNN scikit-learn ‚Äî `ClasificadorKNNSK`
Permite comparar con una implementaci√≥n est√°ndar:
- `KNeighborsClassifier(n_neighbors=k, metric=distancia)`
- `StandardScaler` opcional si `normalizar=True`

## 3) Naive Bayes ‚Äî `ClaificadorNaiveBayes`
**Idea:** asume independencia condicional de atributos dado la clase.

- Calcula a-prioris:
  - `P(clase) = #clase / #total`
- Para atributos nominales:
  - `P(valor | clase)` usando conteo por clase.
  - Laplace opcional (suma 1 al conteo si `laplace=True`).
- Para atributos continuos:
  - Modela `P(x | clase)` con una **Gaussiana**.
  - En esta implementaci√≥n se guardan medias/std por atributo (nota: ver ‚ÄúDetalles a revisar‚Äù).

Predicci√≥n:
- Para cada clase, calcula la probabilidad proporcional:
  - `P(clase) * Œ†_i P(x_i | clase)`
- Devuelve la clase con probabilidad m√°xima.

---

## ‚ñ∂Ô∏è C√≥mo ejecutar

### Opci√≥n A: Notebook (recomendado)
Abrir `MainP1.ipynb` y ejecutar celdas (Jupyter / VS Code).

### Opci√≥n B: Script r√°pido (ejemplo)
Puedes crear un `main.py` con algo as√≠:

```python
from Datos import Datos
from EstrategiaParticionado import ValidacionCruzada
from ClasificadorKNN import ClasificadorKNN
from Clasificador import Clasificador

datos = Datos("tu_dataset.csv", print_val=False)
particionado = ValidacionCruzada(k=5)

knn = ClasificadorKNN(k=5, normalizar=True)
base = Clasificador()  # En la pr√°ctica, llamar√≠as a validaci√≥n desde una instancia concreta o mover√≠as validacion() a funci√≥n util.

# Si prefieres: usa el m√©todo validacion desde una instancia de tu clasificador base
errores = base.validacion(particionado, datos, knn)
print(errores)
print("Media:", sum(errores) / len(errores))
```

> Nota: si vas a usarlo ‚Äúen limpio‚Äù, lo ideal es convertir `validacion(...)` en m√©todo est√°tico o funci√≥n de utilidad y no instanciar `Clasificador` directamente (es abstracta).

---

## üßØ Detalles a revisar (importante si lo publicas)

Hay varias cosas que conviene saber para evitar confusiones:

1) **`error()` realmente calcula precisi√≥n (accuracy), no error**
   - En `Clasificador.error`, se incrementa el contador cuando **acierta**, y se devuelve `aciertos / total`.
   - El nombre ‚Äúerror‚Äù es enga√±oso: devuelve **accuracy**.

2) **`ValidacionSimple.numeroEjecuciones` no se usa**
   - Se crea una sola partici√≥n por llamada.

3) **`seed` no se propaga**
   - `Clasificador.validacion(..., seed=...)` no pasa `seed` a `creaParticiones` (y adem√°s se llama sin seed).
   - Si buscas reproducibilidad, hay que conectarlo.

4) **Naive Bayes continuo: media/std no est√°n condicionadas por clase**
   - El c√≥digo guarda `(media, std)` por atributo usando toda la columna del train (no por clase).
   - En el NB gaussiano ‚Äúcl√°sico‚Äù deber√≠a ser `media/std` **por (atributo, clase)**.
   - Aun as√≠, el notebook muestra resultados razonables, pero esto explica por qu√© podr√≠an no ser los √≥ptimos.

5) **Normalizaci√≥n en KNN propio**
   - Se normaliza cada columna dividiendo por `std`. Si `std == 0` (atributo constante), habr√≠a divisi√≥n por cero (no est√° controlado).

---

## üõ†Ô∏è Dependencias

- `numpy`
- `pandas`
- `scipy` (para distancia eucl√≠dea en KNN propio)
- `scikit-learn` (solo para `ClasificadorKNNSK` y comparativas del notebook)
- Jupyter (si usas el notebook)

---

## üë§ Autor

Santiago de Prada Lorenzo
